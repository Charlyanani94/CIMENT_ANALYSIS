{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP 1 ANANI CHARLY   //          AGOSSOU MENDEL     //         HOUNTON SYLVESTRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application des algorithmes :\n",
    "o Implémenter des méthodes de machine learning (arbre de décision, régression\n",
    "par vecteurs de support, régression polynomiale, régression linéaire, CNN)\n",
    "pour combler les valeurs manquantes.\n",
    "o Comparer les performances des algorithmes à l’aide de métriques telles que le\n",
    "R² , l’erreur quadratique moyenne (RMSE) ou le coefficient de correlation de\n",
    "Pearson r\n",
    "o Justifier le choix de l’algorithme le plus pertinent pour les données étudiées.\n",
    "4. Visualisation des résultats :\n",
    "o Produire des graphiques de distribution des données pour certains paramètres\n",
    "clés.\n",
    "o Présenter les résultats des corrélations et des prédictions sous forme de\n",
    "tableaux ou de diagrammes clairs et professionnels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_one = pd.read_csv('data.csv')\n",
    "data_one.info()\n",
    "data_one.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_one = data_one.drop(data_one.index[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = data_one.copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colonnes dans la copie\n",
    "original_data.rename(columns={\n",
    "'A' : 'date',\n",
    "'B' : 'heure',\n",
    "'C' : 'echelle_alimentation',\n",
    "'D' : 'calcium_libre',\n",
    "'E' : 'test_eligibilite',\n",
    "'F' : 'vitesse_four',\n",
    "'G' : 'echelle_tete_four',\n",
    "'H' : 'echelle_queue_four',\n",
    "'I' : 'temperature_corps',\n",
    "'J' : 'temperature_haut_prechauffeur_1',\n",
    "'K' : 'pression_haut_prechauffeur_1',\n",
    "'L' : 'temperature_bas_prechauffeur_1',\n",
    "'M' : 'pression_bas_prechauffeur_1',\n",
    "'N' : 'temperature_haut_prechauffeur_2',\n",
    "'O' : 'pression_haut_prechauffeur_2',\n",
    "'P' : 'temperature_bas_prechauffeur_2',\n",
    "'Q' : 'pression_bas_prechauffeur_2',\n",
    "'R' : 'temperature_haut_prechauffeur_3',\n",
    "'S' : 'pression_haut_prechauffeur_3',\n",
    "'T' : 'temperature_bas_prechauffeur_3',\n",
    "'U' : 'pression_bas_prechauffeur_3',\n",
    "'V' : 'temperature_haut_prechauffeur_4',\n",
    "'W' : 'pression_haut_prechauffeur_4',\n",
    "'X' : 'temperature_bas_prechauffeur_4',\n",
    "'Y' : 'pression_bas_prechauffeur_4',\n",
    "'Z' : 'temperature_haut_prechauffeur_5',\n",
    "'AA' : 'pression_haut_prechauffeur_5',\n",
    "'AB' : 'temperature_bas_prechauffeur_5',\n",
    "'AC' : 'pression_bas_prechauffeur_5',\n",
    "'AD' : 'temperature_queue_four',\n",
    "'AE' : 'temperature_precalcinateur',\n",
    "'AF' : 'pression_precalcinateur',\n",
    "'AG' : 'ventilateur_principal',\n",
    "'AH' : 'pression_tete_four',\n",
    "'AI' : 'pression_refroidisseur_principal',\n",
    "'AJ' : 'S1_refroidisseur_principal',\n",
    "'AK' : 'I1_refroidisseur_principal',\n",
    "'AL' : 'S1_refroidisseur_secondaire',\n",
    "'AM' : 'I1_refroidisseur_secondaire',\n",
    "'AN' : 'S1_refroidisseur_tertiaire',\n",
    "'AO' : 'I1_refroidisseur_tertiaire',\n",
    "'AP' : 'pression_ventilateur_tertiaire',\n",
    "'AQ' : 'vitesse_ventilateur_hautetemp',\n",
    "'AR' : 'courant_ventilateur_hautetemp'\n",
    "}, inplace=True)\n",
    "\n",
    "print(original_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage direct sur la colonne en utilisant la techniques de map\n",
    "original_data['test_eligibilite'] = original_data['test_eligibilite'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier les colonnes avec des valeurs manquantes\n",
    "valeurs_manquantes_column = original_data.isnull().sum()\n",
    "\n",
    "# Filtrer uniquement les colonnes ayant des valeurs manquantes\n",
    "colonnes_avec_manquants = valeurs_manquantes_column[valeurs_manquantes_column > 0]\n",
    "\n",
    "# Afficher le nombre de valeurs manquantes et leur type\n",
    "print(\"Colonnes avec des valeurs manquantes et leur type :\\n\")\n",
    "for col in colonnes_avec_manquants.index:\n",
    "    print(f\"- {col}: {colonnes_avec_manquants[col]} valeurs manquantes (Type: {original_data[col].dtype})\")\n",
    "\n",
    "# Nombre total de valeurs manquantes\n",
    "valeurs_manquantes = original_data.isnull().values.sum()\n",
    "print(f\"\\nNombre total de valeurs manquantes dans le DataFrame : {valeurs_manquantes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Fonction pour préparer les données\n",
    "def prepare_data(original_data, target_column):\n",
    "    # Calcul de la corrélation uniquement sur les colonnes de données originales\n",
    "    correlation_matrix = original_data.corr()\n",
    "    target_corr = correlation_matrix[target_column]\n",
    "\n",
    "    # Sélectionner les colonnes avec une corrélation d'au moins 0.5\n",
    "    correlated_features = target_corr[abs(target_corr) >= 0.5].index.tolist()\n",
    "    correlated_features.remove(target_column)  # Retirer la colonne cible\n",
    "\n",
    "    # Exclure les colonnes constantes ou avec uniquement des nan\n",
    "    filtered_features = original_data[correlated_features].loc[:, \n",
    "        (original_data[correlated_features].nunique() > 1) & \n",
    "        (original_data[correlated_features].notnull().sum() > 0)\n",
    "    ]\n",
    "\n",
    "    print(f\"On travaille avec la colonne : {target_column}\")\n",
    "    print(f\"Les colonnes corrélées (coef. de corrélation >= 0.5) sont : {correlated_features}\")\n",
    "    print(f\"Colonnes après filtrage : {filtered_features.columns.tolist()}\")\n",
    "\n",
    "    # Inclure uniquement les lignes où la colonne cible et les caractéristiques filtrées ne contiennent pas de valeurs nulles\n",
    "    df_non_missing = original_data[\n",
    "        original_data[target_column].notnull() & \n",
    "        filtered_features.notnull().all(axis=1)\n",
    "    ][filtered_features.columns.tolist() + [target_column]]\n",
    "\n",
    "    # Inclure uniquement les caractéristiques filtrées\n",
    "    features = df_non_missing[filtered_features.columns.tolist()]\n",
    "    targets = df_non_missing[target_column]\n",
    "    \n",
    "    return train_test_split(features, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = original_data.drop(columns=['date', 'heure'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = original_data.drop(columns=['temperature_haut_prechauffeur_3', 'temperature_haut_prechauffeur_4','temperature_bas_prechauffeur_4'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Détection des valeurs aberrantes (exemple avec IQR)\n",
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "\n",
    "# Traitement des valeurs aberrantes dans le DataFrame ''\n",
    "for column in original_data.select_dtypes(include=[np.number]).columns:  # Filtrer uniquement les colonnes numériques\n",
    "    outliers = detect_outliers_iqr(original_data, column)\n",
    "    if not outliers.empty:\n",
    "        median_value = original_data[column].median()\n",
    "        # Remplacer les valeurs aberrantes par la médiane\n",
    "        original_data[column] = np.where((original_data[column] < outliers[column].min()) | (original_data[column] > outliers[column].max()), median_value, original_data[column])\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(original_data.select_dtypes(include=[np.number]))  # Standardiser uniquement les colonnes numériques\n",
    "\n",
    "# Convertir en DataFrame\n",
    "standardized_df = pd.DataFrame(standardized_data, columns=original_data.select_dtypes(include=[np.number]).columns)\n",
    "\n",
    "original_data = standardized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Variable cible\n",
    "target_column = 'calcium_libre'  \n",
    "\n",
    "# Prépar les données\n",
    "X_train, X_temp, y_train, y_temp = prepare_data(original_data, target_column)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Modèle 1 : Arbre de Décision\n",
    "model_dt = DecisionTreeRegressor()\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_dt_val = model_dt.predict(X_val)\n",
    "y_pred_dt_test = model_dt.predict(X_test)\n",
    "\n",
    "# Modèle 2 : Régression par Vecteurs de Support\n",
    "model_svr = SVR()\n",
    "model_svr.fit(X_train, y_train)\n",
    "y_pred_svr_val = model_svr.predict(X_val)\n",
    "y_pred_svr_test = model_svr.predict(X_test)\n",
    "\n",
    "# Modèle 3 : Régression Polynomiale\n",
    "degree = 2\n",
    "model_poly = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "model_poly.fit(X_train, y_train)\n",
    "y_pred_poly_val = model_poly.predict(X_val)\n",
    "y_pred_poly_test = model_poly.predict(X_test)\n",
    "\n",
    "# Modèle 4 : Régression Linéaire\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr_val = model_lr.predict(X_val)\n",
    "y_pred_lr_test = model_lr.predict(X_test)\n",
    "\n",
    "# Modèle 5 : Régression CNN\n",
    "model_cnn = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model_cnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model_cnn.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "y_pred_cnn_val = model_cnn.predict(X_val)\n",
    "y_pred_cnn_test = model_cnn.predict(X_test)\n",
    "\n",
    "# Évaluation sur l'ensemble de validation\n",
    "print(\"Évaluation sur l'ensemble de validation :\")\n",
    "for name, y_pred_val in zip(['Arbre de Décision', 'SVR', 'Régression Polynomiale', 'Régression Linéaire', 'CNN'],\n",
    "                             [y_pred_dt_val, y_pred_svr_val, y_pred_poly_val, y_pred_lr_val, y_pred_cnn_val.flatten()]):\n",
    "    r2 = r2_score(y_val, y_pred_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "    pearson, _ = pearsonr(y_val, y_pred_val)\n",
    "    print(f'{name} - R²: {r2}, RMSE: {rmse}, Pearson r: {pearson}')\n",
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "print(\"\\nÉvaluation sur l'ensemble de test :\")\n",
    "for name, y_pred_test in zip(['Arbre de Décision', 'SVR', 'Régression Polynomiale', 'Régression Linéaire', 'CNN'],\n",
    "                              [y_pred_dt_test, y_pred_svr_test, y_pred_poly_test, y_pred_lr_test, y_pred_cnn_test.flatten()]):\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    pearson, _ = pearsonr(y_test, y_pred_test)\n",
    "    print(f'{name} - R²: {r2}, RMSE: {rmse}, Pearson r: {pearson}')\n",
    "\n",
    "# Validation Croisée\n",
    "print(\"\\nValidation croisée :\")\n",
    "for name, model in zip(['Arbre de Décision', 'SVR', 'Régression Polynomiale', 'Régression Linéaire'],\n",
    "                       [model_dt, model_svr, model_poly, model_lr]):\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    print(f'{name} - R² moyen (validation croisée) : {cv_scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre étude, nous avons analysé la colonne calcium_libre et identifié une corrélation significative avec la colonne test_eligibilite, ayant un coefficient de corrélation supérieur ou égal à 0.5. Après avoir préparé les données en séparant 70% pour l'entraînement et 30% pour la validation et le test, nous avons évalué plusieurs algorithmes de régression : Arbre de Décision, SVR, Régression Polynomiale, Régression Linéaire et Réseaux de Neurones Convolutifs (CNN).\n",
    "\n",
    "Résultats d'Évaluation sur l'Ensemble de Validation\n",
    "Arbre de Décision :\n",
    "\n",
    "Coefficient de détermination = 0.8370\n",
    "RMSE = 0.3937\n",
    "Pearson r = 1.0\n",
    "SVR :\n",
    "\n",
    "Coefficient de détermination = 0.9444\n",
    "RMSE = 0.2301\n",
    "Pearson r = 1.0\n",
    "Régression Polynomiale :\n",
    "\n",
    "Coefficient de détermination = 0.8370\n",
    "RMSE = 0.3937\n",
    "Pearson r = 1.0\n",
    "Régression Linéaire :\n",
    "\n",
    "Coefficient de détermination = 0.8370\n",
    "RMSE = 0.3937\n",
    "Pearson r = 1.0\n",
    "CNN :\n",
    "\n",
    "Coefficient de détermination = 0.8200\n",
    "RMSE = 0.4138\n",
    "Pearson r = 1.0\n",
    "Résultats d'Évaluation sur l'Ensemble de Test\n",
    "Arbre de Décision :\n",
    "\n",
    "Coefficient de détermination = 0.8105\n",
    "RMSE = 0.5142\n",
    "Pearson r = 1.0\n",
    "SVR :\n",
    "\n",
    "Coefficient de détermination = 0.9406\n",
    "RMSE = 0.2878\n",
    "Pearson r = 1.0\n",
    "Régression Polynomiale :\n",
    "\n",
    "Coefficient de détermination = 0.8105\n",
    "RMSE = 0.5142\n",
    "Pearson r = 1.0\n",
    "Régression Linéaire :\n",
    "\n",
    "Coefficient de détermination = 0.8105\n",
    "RMSE = 0.5142\n",
    "Pearson r = 1.0\n",
    "CNN :\n",
    "\n",
    "Coefficient de détermination = 0.7906\n",
    "RMSE = 0.5405\n",
    "Pearson r = 1.0\n",
    "Validation Croisée\n",
    "Arbre de Décision : Coefficient de détermination moyen = 0.4271\n",
    "SVR : Coefficient de détermination moyen = 0.2133\n",
    "Régression Polynomiale : Coefficient de détermination moyen = 0.4271\n",
    "Régression Linéaire : Coefficient de détermination moyen = 0.6271\n",
    "\n",
    "Justification du Choix de l'Algorithme\n",
    "En analysant les résultats, il est évident que le SVR a les meilleures performances, avec un coefficient de détermination dépassant 0.94 sur les ensembles de validation et de test, ainsi qu'un RMSE très faible, indiquant une excellente précision. Les autres algorithmes, bien que performants, n'atteignent pas les mêmes niveaux de précision. De plus, le SVR se distingue par sa capacité à capturer les relations non linéaires entre les variables, ce qui est particulièrement pertinent dans notre cas où la relation entre calcium_libre et test_eligibilite peut être complexe. Par conséquent, le SVR est justifié comme l'algorithme le plus pertinent pour notre analyse, offrant un excellent compromis entre précision et flexibilité pour modéliser les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Variable cible\n",
    "target_column = 'test_eligibilite'  # Remplacez par la bonne colonne\n",
    "\n",
    "# Préparer les données\n",
    "X_train, X_temp, y_train, y_temp = prepare_data(original_data, target_column)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Modèle 1 : Arbre de Décision\n",
    "model_dt = DecisionTreeRegressor()\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_dt_val = model_dt.predict(X_val)\n",
    "y_pred_dt_test = model_dt.predict(X_test)\n",
    "\n",
    "# Modèle 2 : Régression par Vecteurs de Support\n",
    "model_svr = SVR()\n",
    "model_svr.fit(X_train, y_train)\n",
    "y_pred_svr_val = model_svr.predict(X_val)\n",
    "y_pred_svr_test = model_svr.predict(X_test)\n",
    "\n",
    "# Modèle 3 : Régression Polynomiale\n",
    "degree = 2\n",
    "model_poly = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "model_poly.fit(X_train, y_train)\n",
    "y_pred_poly_val = model_poly.predict(X_val)\n",
    "y_pred_poly_test = model_poly.predict(X_test)\n",
    "\n",
    "# Modèle 4 : Régression Linéaire\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr_val = model_lr.predict(X_val)\n",
    "y_pred_lr_test = model_lr.predict(X_test)\n",
    "\n",
    "# Modèle 5 : Régression CNN\n",
    "model_cnn = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model_cnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model_cnn.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "y_pred_cnn_val = model_cnn.predict(X_val)\n",
    "y_pred_cnn_test = model_cnn.predict(X_test)\n",
    "\n",
    "# Évaluation sur l'ensemble de validation\n",
    "print(\"Évaluation sur l'ensemble de validation :\")\n",
    "for name, y_pred_val in zip(['Arbre de Décision', 'SVR', 'Régression Polynomiale', 'Régression Linéaire', 'CNN'],\n",
    "                             [y_pred_dt_val, y_pred_svr_val, y_pred_poly_val, y_pred_lr_val, y_pred_cnn_val.flatten()]):\n",
    "    r2 = r2_score(y_val, y_pred_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "    pearson, _ = pearsonr(y_val, y_pred_val)\n",
    "    print(f'{name} - R²: {r2}, RMSE: {rmse}, Pearson r: {pearson}')\n",
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "print(\"\\nÉvaluation sur l'ensemble de test :\")\n",
    "for name, y_pred_test in zip(['Arbre de Décision', 'SVR', 'Régression Polynomiale', 'Régression Linéaire', 'CNN'],\n",
    "                              [y_pred_dt_test, y_pred_svr_test, y_pred_poly_test, y_pred_lr_test, y_pred_cnn_test.flatten()]):\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    pearson, _ = pearsonr(y_test, y_pred_test)\n",
    "    print(f'{name} - R²: {r2}, RMSE: {rmse}, Pearson r: {pearson}')\n",
    "\n",
    "# Validation Croisée\n",
    "print(\"\\nValidation croisée :\")\n",
    "for name, model in zip(['Arbre de Décision', 'SVR', 'Régression Polynomiale', 'Régression Linéaire'],\n",
    "                       [model_dt, model_svr, model_poly, model_lr]):\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    print(f'{name} - R² moyen (validation croisée) : {cv_scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre étude, nous avons analysé la colonne test_eligibilite et identifié une corrélation significative avec la colonne calcium_libre, ayant un coefficient de corrélation supérieur ou égal à 0.5. Après avoir préparé les données en séparant 70% pour l'entraînement et 30% pour la validation et le test, nous avons évalué plusieurs algorithmes de régression : Arbre de Décision, SVR, Régression Polynomiale, Régression Linéaire et Réseaux de Neurones Convolutifs (CNN).\n",
    "\n",
    "Résultats d'Évaluation sur l'Ensemble de Validation\n",
    "Arbre de Décision :\n",
    "\n",
    "Coefficient de détermination = 0.9969\n",
    "RMSE = 0.0615\n",
    "Pearson r = 1.0\n",
    "SVR :\n",
    "\n",
    "Coefficient de détermination = 0.9918\n",
    "RMSE = 0.0999\n",
    "Pearson r = 1.0\n",
    "Régression Polynomiale :\n",
    "\n",
    "Coefficient de détermination = 0.9966\n",
    "RMSE = 0.0647\n",
    "Pearson r = 1.0\n",
    "Régression Linéaire :\n",
    "\n",
    "Coefficient de détermination = 0.9887\n",
    "RMSE = 0.1174\n",
    "Pearson r = 1.0\n",
    "CNN :\n",
    "\n",
    "Coefficient de détermination = 0.9967\n",
    "RMSE = 0.0638\n",
    "Pearson r = 1.0\n",
    "Résultats d'Évaluation sur l'Ensemble de Test\n",
    "Arbre de Décision :\n",
    "\n",
    "Coefficient de détermination = 0.9982\n",
    "RMSE = 0.0569\n",
    "Pearson r = 1.0\n",
    "SVR :\n",
    "\n",
    "Coefficient de détermination = 0.9944\n",
    "RMSE = 0.0998\n",
    "Pearson r = 1.0\n",
    "Régression Polynomiale :\n",
    "\n",
    "Coefficient de détermination = 0.9980\n",
    "RMSE = 0.0601\n",
    "Pearson r = 1.0\n",
    "Régression Linéaire :\n",
    "\n",
    "Coefficient de détermination = 0.9919\n",
    "RMSE = 0.1203\n",
    "Pearson r = 1.0\n",
    "CNN :\n",
    "\n",
    "Coefficient de détermination = 0.9974\n",
    "RMSE = 0.0679\n",
    "Pearson r = 1.0\n",
    "Validation Croisée\n",
    "Arbre de Décision : Coefficient de détermination moyen = 0.4528\n",
    "SVR : Coefficient de détermination moyen = 0.5087\n",
    "Régression Polynomiale : Coefficient de détermination moyen = -8.377370463172624e+21\n",
    "Régression Linéaire : Coefficient de détermination moyen = 0.4899\n",
    "\n",
    "Justification du Choix de l'Algorithme\n",
    "Après avoir analysé les résultats, il apparaît que l'Arbre de Décision est le meilleur modèle pour prédire la variable test_eligibilite à partir de la variable calcium_libre. En effet, l'Arbre de Décision affiche les meilleures performances sur les ensembles de validation et de test, avec des coefficients de détermination supérieurs à 0.99 et des RMSE très faibles, indiquant une prédiction très précise.\n",
    "\n",
    "De plus, l'Arbre de Décision présente l'avantage d'être un modèle interprétable, permettant de comprendre facilement les relations entre les variables. Bien que la validation croisée montre un coefficient de détermination moyen plus faible, les résultats sur les ensembles de validation et de test sont nettement supérieurs aux autres algorithmes évalués."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Variable cible\n",
    "target_column = 'temperature_haut_prechauffeur_1'  # Remplacez par la bonne colonne\n",
    "\n",
    "# Préparer les données\n",
    "X_train, X_temp, y_train, y_temp = prepare_data(original_data, target_column)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Modèle 1 : Arbre de Décision\n",
    "model_dt = DecisionTreeRegressor()\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_dt_val = model_dt.predict(X_val)\n",
    "y_pred_dt_test = model_dt.predict(X_test)\n",
    "\n",
    "# Modèle 2 : Régression par Vecteurs de Support\n",
    "model_svr = SVR()\n",
    "model_svr.fit(X_train, y_train)\n",
    "y_pred_svr_val = model_svr.predict(X_val)\n",
    "y_pred_svr_test = model_svr.predict(X_test)\n",
    "\n",
    "# Modèle 3 : Régression Polynomiale\n",
    "degree = 2\n",
    "model_poly = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "model_poly.fit(X_train, y_train)\n",
    "y_pred_poly_val = model_poly.predict(X_val)\n",
    "y_pred_poly_test = model_poly.predict(X_test)\n",
    "\n",
    "# Modèle 4 : Régression Linéaire\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr_val = model_lr.predict(X_val)\n",
    "y_pred_lr_test = model_lr.predict(X_test)\n",
    "\n",
    "# Modèle 5 : Régression CNN\n",
    "model_cnn = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model_cnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model_cnn.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "y_pred_cnn_val = model_cnn.predict(X_val)\n",
    "y_pred_cnn_test = model_cnn.predict(X_test)\n",
    "\n",
    "# Évaluation sur l'ensemble de validation\n",
    "print(\"Évaluation sur l'ensemble de validation :\")\n",
    "for name, y_pred_val in zip(['Arbre de Décision', 'SVR', 'Régression Polynomiale', 'Régression Linéaire', 'CNN'],\n",
    "                             [y_pred_dt_val, y_pred_svr_val, y_pred_poly_val, y_pred_lr_val, y_pred_cnn_val.flatten()]):\n",
    "    r2 = r2_score(y_val, y_pred_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "    pearson, _ = pearsonr(y_val, y_pred_val)\n",
    "    print(f'{name} - R²: {r2}, RMSE: {rmse}, Pearson r: {pearson}')\n",
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "print(\"\\nÉvaluation sur l'ensemble de test :\")\n",
    "for name, y_pred_test in zip(['Arbre de Décision', 'SVR', 'Régression Polynomiale', 'Régression Linéaire', 'CNN'],\n",
    "                              [y_pred_dt_test, y_pred_svr_test, y_pred_poly_test, y_pred_lr_test, y_pred_cnn_test.flatten()]):\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    pearson, _ = pearsonr(y_test, y_pred_test)\n",
    "    print(f'{name} - R²: {r2}, RMSE: {rmse}, Pearson r: {pearson}')\n",
    "\n",
    "# Validation Croisée\n",
    "print(\"\\nValidation croisée :\")\n",
    "for name, model in zip(['Arbre de Décision', 'SVR', 'Régression Polynomiale', 'Régression Linéaire'],\n",
    "                       [model_dt, model_svr, model_poly, model_lr]):\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    print(f'{name} - R² moyen (validation croisée) : {cv_scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre étude, nous avons analysé la colonne temperature_haut_prechauffeur_1 et identifié les colonnes corrélées (coefficient de corrélation >= 0.5) : pression_haut_prechauffeur_1, temperature_haut_prechauffeur_2, S1_refroidisseur_principal, I1_refroidisseur_principal et I1_refroidisseur_secondaire. Après avoir préparé les données en séparant 70% pour l'entraînement et 30% pour la validation et le test, nous avons évalué plusieurs algorithmes de régression : Arbre de Décision, SVR, Régression Polynomiale, Régression Linéaire et Réseaux de Neurones Convolutifs (CNN).\n",
    "\n",
    "Résultats d'Évaluation sur l'Ensemble de Validation\n",
    "Arbre de Décision :\n",
    "\n",
    "Coefficient de détermination = 0.7781\n",
    "RMSE = 0.6122\n",
    "Pearson r = 0.9577\n",
    "SVR :\n",
    "\n",
    "Coefficient de détermination = 0.4972\n",
    "RMSE = 0.9215\n",
    "Pearson r = 0.9621\n",
    "Régression Polynomiale :\n",
    "\n",
    "Coefficient de détermination = 0.2885\n",
    "RMSE = 1.0962\n",
    "Pearson r = 0.5704\n",
    "Régression Linéaire :\n",
    "\n",
    "Coefficient de détermination = 0.5186\n",
    "RMSE = 0.9017\n",
    "Pearson r = 0.9731\n",
    "CNN :\n",
    "\n",
    "Coefficient de détermination = 0.6962\n",
    "RMSE = 0.7163\n",
    "Pearson r = 0.9913\n",
    "Résultats d'Évaluation sur l'Ensemble de Test\n",
    "Arbre de Décision :\n",
    "\n",
    "Coefficient de détermination = 0.9780\n",
    "RMSE = 0.1149\n",
    "Pearson r = 0.9959\n",
    "SVR :\n",
    "\n",
    "Coefficient de détermination = 0.7551\n",
    "RMSE = 0.3837\n",
    "Pearson r = 0.8913\n",
    "Régression Polynomiale :\n",
    "\n",
    "Coefficient de détermination = 0.1740\n",
    "RMSE = 0.7047\n",
    "Pearson r = 0.5519\n",
    "Régression Linéaire :\n",
    "\n",
    "Coefficient de détermination = 0.6999\n",
    "RMSE = 0.4248\n",
    "Pearson r = 0.9046\n",
    "CNN :\n",
    "\n",
    "Coefficient de détermination = 0.8126\n",
    "RMSE = 0.3357\n",
    "Pearson r = 0.9033\n",
    "Validation Croisée\n",
    "Arbre de Décision : Coefficient de détermination moyen = 0.4081\n",
    "SVR : Coefficient de détermination moyen = 0.5916\n",
    "Régression Polynomiale : Coefficient de détermination moyen = -2.0258\n",
    "Régression Linéaire : Coefficient de détermination moyen = 0.5269\n",
    "\n",
    "Justification du Choix de l'Algorithme\n",
    "Après avoir analysé les résultats, il apparaît que l'Arbre de Décision est le meilleur modèle pour prédire la variable temperature_haut_prechauffeur_1 à partir des variables corrélées. En effet, l'Arbre de Décision affiche les meilleures performances sur les ensembles de validation et de test, avec des coefficients de détermination élevés (0.7781 et 0.9780 respectivement) et des RMSE relativement faibles.\n",
    "\n",
    "De plus, l'Arbre de Décision présente l'avantage d'être un modèle interprétable, permettant de comprendre facilement les relations entre les variables. Bien que la validation croisée montre un coefficient de détermination moyen plus faible, les résultats sur les ensembles de validation et de test sont nettement supérieurs aux autres algorithmes évalués.\n",
    "\n",
    "Par conséquent, l'Arbre de Décision est le modèle le plus pertinent pour prédire la variable temperature_haut_prechauffeur_1 à partir des variables corrélées, offrant un excellent compromis entre précision, interprétabilité et robustesse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Synthese pour els trois varaibels Au cours de cette étude, nous avons analysé trois variables cibles différentes : test_eligibilite, calcium_libre et temperature_haut_prechauffeur_1. Pour chacune de ces variables, nous avons identifié les colonnes corrélées (coefficient de corrélation >= 0.5) et procédé à l'évaluation de plusieurs algorithmes de régression : Arbre de Décision, SVR, Régression Polynomiale, Régression Linéaire et Réseaux de Neurones Convolutifs (CNN).\n",
    "\n",
    "Les résultats obtenus montrent que l'Arbre de Décision est le modèle le plus performant pour prédire les variables test_eligibilite et temperature_haut_prechauffeur_1. En effet, l'Arbre de Décision a affiché les meilleurs coefficients de détermination, les plus faibles RMSE et les plus hauts coefficients de corrélation de Pearson, tant sur les ensembles de validation que de test.\n",
    "\n",
    "Cependant, pour la variable calcium_libre, le modèle SVR s'est révélé le plus performant, avec de meilleurs résultats que l'Arbre de Décision sur les ensembles de validation et de test.\n",
    "\n",
    "De plus, l'Arbre de Décision présente l'avantage d'être un modèle facilement interprétable, permettant de comprendre les relations entre les variables. Bien que les résultats de validation croisée soient plus mitigés, les performances sur les ensembles de validation et de test sont nettement supérieures aux autres algorithmes évalués, à l'exception du modèle SVR pour la prédiction du calcium_libre.\n",
    "\n",
    "En conclusion, l'Arbre de Décision semble être le modèle le plus adapté pour prédire les variables test_eligibilite et temperature_haut_prechauffeur_1, tandis que le modèle SVR est le plus performant pour prédire la variable calcium_libre. Ces modèles offrent un excellent compromis entre précision, interprétabilité et robustesse, les rendant ainsi les plus pertinents pour ces problématiques de régression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##visualisation des resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Définir le style de seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Création des graphiques de distribution\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Graphique pour echelle_alimentation\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.histplot(original_data['echelle_alimentation'].dropna(), kde=True, color='blue')\n",
    "plt.title('Distribution de l\\'Échelle d\\'Alimentation')\n",
    "plt.xlabel('Échelle d\\'Alimentation')\n",
    "plt.ylabel('Fréquence')\n",
    "\n",
    "# Graphique pour calcium_libre\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.histplot(original_data['calcium_libre'].dropna(), kde=True, color='orange')\n",
    "plt.title('Distribution de Calcium Libre')\n",
    "plt.xlabel('Calcium Libre')\n",
    "plt.ylabel('Fréquence')\n",
    "\n",
    "# Graphique pour test_eligibilite\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.histplot(original_data['test_eligibilite'].dropna(), kde=True, color='green')\n",
    "plt.title('Distribution de Test Éligibilité')\n",
    "plt.xlabel('Test Éligibilité')\n",
    "plt.ylabel('Fréquence')\n",
    "\n",
    "# Graphique pour vitesse_four\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.histplot(original_data['vitesse_four'].dropna(), kde=True, color='purple')\n",
    "plt.title('Distribution de Vitesse du Four')\n",
    "plt.xlabel('Vitesse du Four')\n",
    "plt.ylabel('Fréquence')\n",
    "\n",
    "# Graphique pour temperature_corps\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.histplot(original_data['temperature_corps'].dropna(), kde=True, color='red')\n",
    "plt.title('Distribution de Température du Corps')\n",
    "plt.xlabel('Température du Corps')\n",
    "plt.ylabel('Fréquence')\n",
    "\n",
    "# Graphique pour pression_precalcinateur\n",
    "plt.subplot(2, 3, 6)\n",
    "sns.histplot(original_data['pression_precalcinateur'].dropna(), kde=True, color='cyan')\n",
    "plt.title('Distribution de Pression du Pré-calcinateur')\n",
    "plt.xlabel('Pression du Pré-calcinateur')\n",
    "plt.ylabel('Fréquence')\n",
    "\n",
    "# Ajuster l'affichage\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Définir le style de seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Création des graphiques de distribution\n",
    "plt.figure(figsize=(15, 10))\n",
    "# Graphique pour temperature_haut_prechauffeur_1\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.histplot(original_data['temperature_haut_prechauffeur_1'].dropna(), kde=True, color='brown')\n",
    "plt.title('Distribution de Température Haut Préchauffeur 1')\n",
    "plt.xlabel('Température Haut Préchauffeur 1')\n",
    "plt.ylabel('Fréquence')\n",
    "\n",
    "# Graphique pour temperature_haut_prechauffeur_2\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.histplot(original_data['temperature_haut_prechauffeur_2'].dropna(), kde=True, color='pink')\n",
    "plt.title('Distribution de Température Haut Préchauffeur 2')\n",
    "plt.xlabel('Température Haut Préchauffeur 2')\n",
    "plt.ylabel('Fréquence')\n",
    "\n",
    "# Graphique pour pression_bas_prechauffeur_4\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.histplot(original_data['pression_bas_prechauffeur_4'].dropna(), kde=True, color='gray')\n",
    "plt.title('Distribution de Pression Bas Préchauffeur 4')\n",
    "plt.xlabel('Pression Bas Préchauffeur 4')\n",
    "plt.ylabel('Fréquence')\n",
    "\n",
    "# Graphique pour I1_refroidisseur_principal\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.histplot(original_data['I1_refroidisseur_principal'].dropna(), kde=True, color='olive')\n",
    "plt.title('Distribution de I1 Refroidisseur Principal')\n",
    "plt.xlabel('I1 Refroidisseur Principal')\n",
    "plt.ylabel('Fréquence')\n",
    "\n",
    "# Graphique pour I1_refroidisseur_secondaire\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.histplot(original_data['I1_refroidisseur_secondaire'].dropna(), kde=True, color='navy')\n",
    "plt.title('Distribution de I1 Refroidisseur Secondaire')\n",
    "plt.xlabel('I1 Refroidisseur Secondaire')\n",
    "plt.ylabel('Fréquence')\n",
    "\n",
    "# Graphique pour pression_ventilateur_tertiaire\n",
    "plt.subplot(2, 3, 6)\n",
    "sns.histplot(original_data['pression_ventilateur_tertiaire'].dropna(), kde=True, color='magenta')\n",
    "plt.title('Distribution de Pression Ventilateur Tertiaire')\n",
    "plt.xlabel('Pression Ventilateur Tertiaire')\n",
    "plt.ylabel('Fréquence')\n",
    "\n",
    "# Ajuster l'affichage\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legendes\n",
    "\n",
    "Échelle d'Alimentation (echelle_alimentation) :\n",
    "\n",
    "Signification : Proportion des ingrédients utilisés dans le processus.\n",
    "Importance : Assure la bonne proportion des ingrédients pour garantir la qualité du produit final.\n",
    "Calcium Libre (calcium_libre) :\n",
    "\n",
    "Signification : Mesure du calcium disponible dans les matières premières.\n",
    "Importance : Indicateur de la qualité des matières premières, essentiel pour certaines réactions chimiques.\n",
    "Test d'Éligibilité (test_eligibilite) :\n",
    "\n",
    "Signification : Vérification de la conformité des matériaux aux spécifications requises.\n",
    "Importance : Assure que les matériaux utilisés répondent aux normes nécessaires pour le processus de production.\n",
    "Vitesse du Four (vitesse_four) :\n",
    "\n",
    "Signification : Vitesse à laquelle les matériaux passent à travers le four.\n",
    "Importance : Influence les conditions de traitement thermique et la qualité du produit final.\n",
    "Température du Corps (temperature_corps) :\n",
    "\n",
    "Signification : Température à l'intérieur du four ou d'un autre équipement.\n",
    "Importance : Crucial pour les réactions chimiques et le maintien des conditions optimales de production.\n",
    "\n",
    "Pression du Pré-calcinateur (pression_precalcinateur) :\n",
    "\n",
    "Signification : Pression dans le pré-calcinateur, qui prépare les matériaux avant leur passage dans le four.\n",
    "Importance : Influence les réactions chimiques et la qualité du produit final.\n",
    "\n",
    "Pression Bas Préchauffeur 4 (pression_bas_prechauffeur_4)\n",
    "Signification : Pression mesurée au bas du quatrième préchauffeur.\n",
    "Importance : Affecte la circulation des gaz et l'efficacité du processus de préchauffage.\n",
    "\n",
    "Température Haut Préchauffeur 1 (temperature_haut_prechauffeur_1)\n",
    "Signification : Température maximale dans le premier préchauffeur.\n",
    "Importance : Impacte l'efficacité énergétique et le préchauffage des matériaux avant leur passage dans le four.\n",
    "\n",
    "\n",
    "Température Haut Préchauffeur 2 (temperature_haut_prechauffeur_2)\n",
    "Signification : Température maximale dans le deuxième préchauffeur.\n",
    "Importance : Essentielle pour assurer un chauffage progressif et homogène des matières premières.\n",
    "\n",
    "\n",
    "I1 Refroidisseur Principal (I1_refroidisseur_principal)\n",
    "Signification : Indicateur de performance du refroidisseur principal de clinker.\n",
    "Importance : Influence la rapidité et l'efficacité du refroidissement du clinker, un facteur clé pour la qualité du ciment.\n",
    "\n",
    "\n",
    "I1 Refroidisseur Secondaire (I1_refroidisseur_secondaire)\n",
    "Signification : Indicateur de performance du refroidisseur secondaire de clinker.\n",
    "Importance : Complète le refroidissement du clinker, impactant sa stabilité avant le stockage.\n",
    "\n",
    "\n",
    "Pression Ventilateur Tertiaire (pression_ventilateur_tertiaire)\n",
    "Signification : Pression générée par le ventilateur tertiaire.\n",
    "Importance : Affecte la circulation des gaz et l’apport d’oxygène dans le four, influençant l’efficacité thermique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution de l'Échelle d'Alimentation interpretation selon els valeurs reeles et non ceux standardiser \n",
    "\n",
    "\n",
    "les valeurs utiliser ici sont les valeurd reeeles et nnon ceux standardiser l'allure des courbes etant la meme dans les deux cas \n",
    "\n",
    "L'échelle d'alimentation est centrée autour de 410, avec une forte concentration des valeurs à cet endroit.\n",
    "Il y a peu de valeurs en dehors de cette plage, ce qui indique une distribution asymétrique avec une légère dispersion vers la droite.\n",
    "La densité montre un pic marqué autour de 410, ce qui signifie que la plupart des observations se trouvent ici.\n",
    "\n",
    "\n",
    "Distribution de Calcium Libre \n",
    "\n",
    "Les valeurs sont très concentrées à gauche (autour de 0 et 2) avec une longue traîne vers la droite.\n",
    "Cela indique une distribution asymétrique où la majorité des observations ont une faible teneur en calcium libre.\n",
    "Quelques valeurs extrêmes existent vers 10, suggérant des cas inhabituels.\n",
    "\n",
    "\n",
    "\n",
    "Distribution de Test Éligibilité \n",
    "\n",
    "La majorité des valeurs se trouvent autour de 1, avec une très faible présence en dessous de 0.8.\n",
    "Cela suggère que la plupart des échantillons sont considérés comme éligibles, avec très peu de rejets.\n",
    "La densité suit la même tendance, montrant une nette concentration des valeurs à l’extrémité droite.\n",
    "\n",
    "\n",
    "Distribution de Vitesse du Four \n",
    "\n",
    "La vitesse est fortement concentrée autour de 3.88, avec très peu de dispersion.\n",
    "La densité suit une asymétrie similaire à celle observée dans le test d’éligibilité, ce qui montre que les variations sont faibles et les valeurs hors de cette plage sont rares.\n",
    "\n",
    "\n",
    "Distribution de Température du Corps \n",
    "\n",
    "La température du corps suit une distribution relativement normale avec un pic autour de 370.\n",
    "Il y a une certaine dispersion avec des valeurs allant de 350 à 390, mais la majorité des valeurs sont centrées vers la moyenne.\n",
    "La courbe de densité montre que les valeurs autour de 370 sont les plus fréquentes.\n",
    "\n",
    "\n",
    "\n",
    "Distribution de Pression du Pré-calcinateur \n",
    "\n",
    "La distribution est multimodale avec plusieurs pics, ce qui suggère plusieurs groupes de pression distincts.\n",
    "Les valeurs sont concentrées entre 0.6 et 0.9, avec un creux autour de 0.75.\n",
    "Cela pourrait indiquer différentes conditions de fonctionnement du pré-calcinateur.\n",
    "\n",
    "On applique une analyse simialires aux autre variables \n",
    "\n",
    "\n",
    "Certaines distributions sont asymétriques (comme le calcium libre et le test d’éligibilité), ce qui peut indiquer des seuils critiques ou des tendances spécifiques.\n",
    "D'autres distributions sont fortement concentrées autour d'une valeur spécifique (échelle d'alimentation et vitesse du four), ce qui montre une faible variabilité.\n",
    "La température du corps suit une distribution presque normale, ce qui peut être utile pour l'analyse prédictive.\n",
    "La pression du pré-calcinateur présente plusieurs modes, indiquant peut-être plusieurs états de fonctionnement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"

  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
